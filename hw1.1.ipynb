{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### PREPROCESS TXTs WITH DATA AND PRODUCE PICKLES BY MONTHS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import bz2\n",
    "from pathlib import Path"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dateparse = lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_path = Path('./data/').resolve()\n",
    "filenumber = '11'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "colunms = [s for s in 'date;id_doc;id_order;id_card;id_tov;id_kontr;quantity;sum;is_green'.split(';')]\n",
    "colunms"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_chunks = pd.read_csv(\n",
    "    filepath_or_buffer= data_path / (filenumber + '.txt'),\n",
    "    header=0,\n",
    "    sep=';',\n",
    "    names = colunms,\n",
    "    usecols = colunms,\n",
    "    parse_dates=['date'],\n",
    "    date_parser=dateparse,\n",
    "    chunksize=1000000,\n",
    "    # skiprows=274011\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with bz2.open(data_path / 'card_lbe.pkl.bz2', 'rb') as f:\n",
    "    card_mapper = pickle.load(f)\n",
    "card_mapper.id_card = card_mapper.id_card.str.strip()\n",
    "card_mapper.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with bz2.open(data_path / 'doc_lbe.pkl.bz2', 'rb') as f:\n",
    "    doc_mapper = pickle.load(f)\n",
    "doc_mapper.id_doc = doc_mapper.id_doc.str.strip()\n",
    "doc_mapper.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def map_data(df, card_mapper, doc_mapper):\n",
    "    df.id_card = df.id_card.str.strip()\n",
    "    df.id_doc = df.id_doc.str.strip()\n",
    "\n",
    "    df = pd.merge(df, card_mapper, on='id_card', how='left')\n",
    "    df = pd.merge(df, doc_mapper, on='id_doc', how='left')\n",
    "\n",
    "    del df['id_card']\n",
    "    del df['id_doc']\n",
    "\n",
    "    return df\n",
    "\n",
    "def cleanup_data(df):\n",
    "    na_int_val = -9999\n",
    "    df['quantity'] = df['quantity'].str.replace(',', '.').astype(float)\n",
    "    df['sum'] = df['sum'].str.replace(',', '.').astype(float)\n",
    "    df['is_green'] = df['is_green'].astype('bool')\n",
    "    df['id_kontr'] = df['id_kontr'].fillna(na_int_val).astype(int)\n",
    "\n",
    "    print(df.dtypes)\n",
    "\n",
    "    if df.isnull().values.any():\n",
    "        print(\"ERROR: THERE ARE STILL NULL VALUES\")\n",
    "        print(df.loc[:, df.isnull().any()].columns)\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for chunk in df_chunks:\n",
    "    chunk = map_data(chunk, card_mapper, doc_mapper)\n",
    "    chunk = cleanup_data(chunk)\n",
    "    print(chunk.head())\n",
    "    with bz2.open(data_path / (filenumber + '_myprepared.pkl.bz2'), 'ab') as f:\n",
    "        pickle.dump(chunk, f, protocol=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### FIND BAD CARD IDS AND SAVE TO TXT"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unusual-spray",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import gc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "import bz2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "circular-england",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "data_path = Path('./data/').resolve()\n",
    "!ls {data_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "honest-insulation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                 date                                id_doc  id_order  \\\n0 2020-11-01 15:29:01  2220AF19-3E1C-EB11-B444-005056A7539A         0   \n1 2020-11-01 12:41:10  F102DC7D-261C-EB11-B444-005056A7539A   8293317   \n2 2020-11-01 13:17:09  4632D419-2C1C-EB11-B444-005056A7539A         0   \n3 2020-11-01 12:31:31  706B9E66-251C-EB11-B444-005056A7539A         0   \n4 2020-11-01 13:06:15  71F3E090-2A1C-EB11-B444-005056A7539A         0   \n\n   id_card  id_tov  id_kontr  quantity     sum  is_green  id_card_int  \\\n0  1826606      52       271       1.0  107.98     False       332351   \n1  C560312      52     -9999       1.0  108.00     False      1875438   \n2  3225041      61       379       2.0  112.00     False       563112   \n3  B700679      61       379       1.0   55.91     False      1841710   \n4  7024046      61       271       2.0   87.80     False      1304277   \n\n   id_doc_int  \n0     3121751  \n1    22047017  \n2     6419825  \n3    10284541  \n4    10424967  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>id_doc</th>\n      <th>id_order</th>\n      <th>id_card</th>\n      <th>id_tov</th>\n      <th>id_kontr</th>\n      <th>quantity</th>\n      <th>sum</th>\n      <th>is_green</th>\n      <th>id_card_int</th>\n      <th>id_doc_int</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-11-01 15:29:01</td>\n      <td>2220AF19-3E1C-EB11-B444-005056A7539A</td>\n      <td>0</td>\n      <td>1826606</td>\n      <td>52</td>\n      <td>271</td>\n      <td>1.0</td>\n      <td>107.98</td>\n      <td>False</td>\n      <td>332351</td>\n      <td>3121751</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-11-01 12:41:10</td>\n      <td>F102DC7D-261C-EB11-B444-005056A7539A</td>\n      <td>8293317</td>\n      <td>C560312</td>\n      <td>52</td>\n      <td>-9999</td>\n      <td>1.0</td>\n      <td>108.00</td>\n      <td>False</td>\n      <td>1875438</td>\n      <td>22047017</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-11-01 13:17:09</td>\n      <td>4632D419-2C1C-EB11-B444-005056A7539A</td>\n      <td>0</td>\n      <td>3225041</td>\n      <td>61</td>\n      <td>379</td>\n      <td>2.0</td>\n      <td>112.00</td>\n      <td>False</td>\n      <td>563112</td>\n      <td>6419825</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-11-01 12:31:31</td>\n      <td>706B9E66-251C-EB11-B444-005056A7539A</td>\n      <td>0</td>\n      <td>B700679</td>\n      <td>61</td>\n      <td>379</td>\n      <td>1.0</td>\n      <td>55.91</td>\n      <td>False</td>\n      <td>1841710</td>\n      <td>10284541</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-11-01 13:06:15</td>\n      <td>71F3E090-2A1C-EB11-B444-005056A7539A</td>\n      <td>0</td>\n      <td>7024046</td>\n      <td>61</td>\n      <td>271</td>\n      <td>2.0</td>\n      <td>87.80</td>\n      <td>False</td>\n      <td>1304277</td>\n      <td>10424967</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with bz2.open(data_path / '11_prepared.pkl.bz2', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "collaborative-nylon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                 date  id_order  id_tov  id_kontr  quantity     sum  is_green  \\\n0 2020-11-01 15:29:01         0      52       271       1.0  107.98     False   \n1 2020-11-01 12:41:10   8293317      52     -9999       1.0  108.00     False   \n2 2020-11-01 13:17:09         0      61       379       2.0  112.00     False   \n3 2020-11-01 12:31:31         0      61       379       1.0   55.91     False   \n4 2020-11-01 13:06:15         0      61       271       2.0   87.80     False   \n\n   id_card_int  id_doc_int  \n0       332351     3121751  \n1      1875438    22047017  \n2       563112     6419825  \n3      1841710    10284541  \n4      1304277    10424967  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>id_order</th>\n      <th>id_tov</th>\n      <th>id_kontr</th>\n      <th>quantity</th>\n      <th>sum</th>\n      <th>is_green</th>\n      <th>id_card_int</th>\n      <th>id_doc_int</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-11-01 15:29:01</td>\n      <td>0</td>\n      <td>52</td>\n      <td>271</td>\n      <td>1.0</td>\n      <td>107.98</td>\n      <td>False</td>\n      <td>332351</td>\n      <td>3121751</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-11-01 12:41:10</td>\n      <td>8293317</td>\n      <td>52</td>\n      <td>-9999</td>\n      <td>1.0</td>\n      <td>108.00</td>\n      <td>False</td>\n      <td>1875438</td>\n      <td>22047017</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-11-01 13:17:09</td>\n      <td>0</td>\n      <td>61</td>\n      <td>379</td>\n      <td>2.0</td>\n      <td>112.00</td>\n      <td>False</td>\n      <td>563112</td>\n      <td>6419825</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-11-01 12:31:31</td>\n      <td>0</td>\n      <td>61</td>\n      <td>379</td>\n      <td>1.0</td>\n      <td>55.91</td>\n      <td>False</td>\n      <td>1841710</td>\n      <td>10284541</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-11-01 13:06:15</td>\n      <td>0</td>\n      <td>61</td>\n      <td>271</td>\n      <td>2.0</td>\n      <td>87.80</td>\n      <td>False</td>\n      <td>1304277</td>\n      <td>10424967</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['id_card', 'id_doc'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                 date  id_order  id_tov  id_kontr  quantity    sum  is_green  \\\n0 2020-11-23 16:20:14         0   18968     21847       1.0  149.0     False   \n1 2020-11-09 21:07:55   8806483   22516     -9999       2.0   62.0     False   \n2 2020-11-15 19:30:37         0   19120       131       1.0   35.0     False   \n3 2020-11-21 18:50:30         0   27494     18670       1.0   93.0      True   \n4 2020-11-06 11:53:41   8582923   34071     13997       1.0  135.0     False   \n\n   id_card_int  id_doc_int  \n0       276039    20875398  \n1      1284109    16188924  \n2      1358347     5985850  \n3      1426130      370379  \n4       535985    18268849  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>id_order</th>\n      <th>id_tov</th>\n      <th>id_kontr</th>\n      <th>quantity</th>\n      <th>sum</th>\n      <th>is_green</th>\n      <th>id_card_int</th>\n      <th>id_doc_int</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-11-23 16:20:14</td>\n      <td>0</td>\n      <td>18968</td>\n      <td>21847</td>\n      <td>1.0</td>\n      <td>149.0</td>\n      <td>False</td>\n      <td>276039</td>\n      <td>20875398</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-11-09 21:07:55</td>\n      <td>8806483</td>\n      <td>22516</td>\n      <td>-9999</td>\n      <td>2.0</td>\n      <td>62.0</td>\n      <td>False</td>\n      <td>1284109</td>\n      <td>16188924</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-11-15 19:30:37</td>\n      <td>0</td>\n      <td>19120</td>\n      <td>131</td>\n      <td>1.0</td>\n      <td>35.0</td>\n      <td>False</td>\n      <td>1358347</td>\n      <td>5985850</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-11-21 18:50:30</td>\n      <td>0</td>\n      <td>27494</td>\n      <td>18670</td>\n      <td>1.0</td>\n      <td>93.0</td>\n      <td>True</td>\n      <td>1426130</td>\n      <td>370379</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-11-06 11:53:41</td>\n      <td>8582923</td>\n      <td>34071</td>\n      <td>13997</td>\n      <td>1.0</td>\n      <td>135.0</td>\n      <td>False</td>\n      <td>535985</td>\n      <td>18268849</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "46496621"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "bad_cards = set()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def find_bad_id_cards(chunk):\n",
    "    bad_cards.update(chunk[chunk['sum'] < 0]['id_card_int'].unique())\n",
    "    bad_cards.update(chunk[chunk['quantity'] < 0]['id_card_int'].unique())\n",
    "    bad_cards.update(chunk[chunk['is_green'] < 0]['id_card_int'].unique())\n",
    "    bad_cards.update(chunk[chunk['id_tov'] < 0]['id_card_int'].unique())\n",
    "    bad_cards.update(chunk[chunk['id_order'] < 0]['id_card_int'].unique())\n",
    "    bad_cards.update(chunk[(chunk['id_kontr'] < 0) & (chunk['id_kontr'] != -9999)]['id_card_int'].unique())\n",
    "    \n",
    "    card_unique_days = chunk.groupby(['id_card_int'])['day'].nunique()\n",
    "    card_unique_days = card_unique_days.sort_values(ascending=False)\n",
    "    card_unique_days = pd.DataFrame(card_unique_days)\n",
    "    bad_days = card_unique_days[card_unique_days['day'] > 15].reset_index()\n",
    "    bad_cards.update(bad_days['id_card_int'].unique())\n",
    "    # print(bad_days['id_card_int'].unique())\n",
    "\n",
    "    doc_card_day_sum_grouped = chunk.groupby(['id_card_int','day'])\n",
    "    cards_sum_by_days = doc_card_day_sum_grouped.sum()\n",
    "    cards_sum_by_days = cards_sum_by_days.reset_index()\n",
    "    \n",
    "    bad_cards.update(cards_sum_by_days[cards_sum_by_days['sum'] > 50000]['id_card_int'].unique())\n",
    "    bad_cards.update(cards_sum_by_days[cards_sum_by_days['quantity'] > 1000]['id_card_int'].unique())\n",
    "\n",
    "def write_bad_ids_to_file_smart(file_name):\n",
    "    known_bad_ids = set()\n",
    "    with open(data_path / file_name, 'r') as input_file:\n",
    "        for item in input_file.readlines():\n",
    "            known_bad_ids.add(int(item.strip()))\n",
    "\n",
    "    known_bad_ids.update(bad_cards)\n",
    "\n",
    "    with open(data_path / file_name, 'w') as output_file:\n",
    "        for item in known_bad_ids:\n",
    "            output_file.write(str(item) + \"\\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 2000000\n",
    "OUTPUT_TXT_NAME = 'bad_ids.txt'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFiles\\miniconda3\\envs\\Torch1.4\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\ProgramFiles\\miniconda3\\envs\\Torch1.4\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\ProgramFiles\\miniconda3\\envs\\Torch1.4\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\ProgramFiles\\miniconda3\\envs\\Torch1.4\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\ProgramFiles\\miniconda3\\envs\\Torch1.4\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\ProgramFiles\\miniconda3\\envs\\Torch1.4\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\ProgramFiles\\miniconda3\\envs\\Torch1.4\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\ProgramFiles\\miniconda3\\envs\\Torch1.4\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\ProgramFiles\\miniconda3\\envs\\Torch1.4\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\ProgramFiles\\miniconda3\\envs\\Torch1.4\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\ProgramFiles\\miniconda3\\envs\\Torch1.4\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\ProgramFiles\\miniconda3\\envs\\Torch1.4\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\ProgramFiles\\miniconda3\\envs\\Torch1.4\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\ProgramFiles\\miniconda3\\envs\\Torch1.4\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\ProgramFiles\\miniconda3\\envs\\Torch1.4\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\ProgramFiles\\miniconda3\\envs\\Torch1.4\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\ProgramFiles\\miniconda3\\envs\\Torch1.4\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\ProgramFiles\\miniconda3\\envs\\Torch1.4\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\ProgramFiles\\miniconda3\\envs\\Torch1.4\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\ProgramFiles\\miniconda3\\envs\\Torch1.4\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\ProgramFiles\\miniconda3\\envs\\Torch1.4\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\ProgramFiles\\miniconda3\\envs\\Torch1.4\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\ProgramFiles\\miniconda3\\envs\\Torch1.4\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\ProgramFiles\\miniconda3\\envs\\Torch1.4\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for chunk_id in range((len(df) + CHUNK_SIZE - 1) // CHUNK_SIZE):\n",
    "    chunk = df[chunk_id * CHUNK_SIZE : (chunk_id + 1) * CHUNK_SIZE]\n",
    "    chunk['day'] = chunk['date'].dt.date\n",
    "    find_bad_id_cards(chunk)\n",
    "    write_bad_ids_to_file_smart(OUTPUT_TXT_NAME)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TRANSFORM TXT OUTPUT TO PICKLE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def copy_from_txt_to_pickle(file_name):\n",
    "    known_bad_ids = set()\n",
    "    with open(data_path / file_name, 'r') as input_file:\n",
    "        for item in input_file.readlines():\n",
    "            known_bad_ids.add(int(item.strip()))\n",
    "\n",
    "    df_txt = pd.DataFrame({'id_card_int' : list(known_bad_ids)})\n",
    "    print(df_txt)\n",
    "    with bz2.open(data_path / 'hw1.1.pkl.bz2', 'wb') as f:\n",
    "        pickle.dump(df_txt, f, protocol=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "copy_from_txt_to_pickle(OUTPUT_TXT_NAME)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SOME TRASH NEXT. I ANALYZED STATISTICS THERE, NOW IT IS BROKEN."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-violin",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "n, bins, rectangles = ax.hist(card_unique_days, 50)\n",
    "fig.canvas.draw()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame(card_unique_days).boxplot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "good_cards = card_unique_days[card_unique_days['day'] <= 15]\n",
    "good_cards = good_cards.reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chunk['id_card_int'].nunique() - len(good_cards)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-transaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bad_cards = bad_cards.reset_index()\n",
    "100*(len(bad_cards) / len(chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-state",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_good_cards = set(good_cards['id_card_int'])\n",
    "doc_card_day_sum_clean = chunk[chunk.id_card_int.isin(list_good_cards)]\n",
    "len(doc_card_day_sum_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-white",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doc_card_day_sum_clean['id_card_int'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-purse",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_card_day_sum_clean_grouped = doc_card_day_sum_clean.groupby(['id_card_int','day'])\n",
    "doc_card_day_sum_clean_grouped_sum = doc_card_day_sum_clean_grouped.sum()\n",
    "doc_card_day_sum_clean_grouped_sum_index = doc_card_day_sum_clean_grouped_sum.reset_index()\n",
    "doc_card_day_sum_clean_grouped_sum_index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(doc_card_day_sum_clean_grouped_sum_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(doc_card_day_sum_clean)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "doc_card_day_sum_clean_grouped_sum_index.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cards = doc_card_day_sum_clean_grouped_sum_index[doc_card_day_sum_clean_grouped_sum_index['id_card_int'] == 100]\n",
    "cards.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cards = doc_card_day_sum_clean[(doc_card_day_sum_clean['id_card_int'] == 100) & (doc_card_day_sum_clean['date'] >= '2020-09-24')]\n",
    "cards.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-delicious",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_card_day_sum_clean_grouped_sum_index.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-merchandise",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_card_day_sum_clean_grouped_sum_index.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-press",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    np.percentile(doc_card_day_sum_clean_grouped_sum_index['sum'], q=75),\n",
    "    np.percentile(doc_card_day_sum_clean_grouped_sum_index['sum'], q=95),\n",
    "    np.percentile(doc_card_day_sum_clean_grouped_sum_index['sum'], q=99)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-madness",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(doc_card_day_sum_clean['is_green']).boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-greeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_card_day_sum_clean_grouped_sum_index[doc_card_day_sum_clean_grouped_sum_index['sum'] > 5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-singapore",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_cards = doc_card_day_sum_clean_grouped_sum_index[doc_card_day_sum_clean_grouped_sum_index['sum'] > 10000]\n",
    "bad_cards = list(bad_cards['id_card_int'].unique())\n",
    "final_clean = doc_card_day_sum_clean_grouped_sum_index[~doc_card_day_sum_clean_grouped_sum_index.id_card_int.isin(bad_cards)]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "n, bins, rectangles = ax.hist(final_clean['sum'], 50)\n",
    "fig.canvas.draw()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(final_clean['quantity']).boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_clean.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame(final_clean['id_kontr']).boxplot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bad_cards = final_clean[(final_clean['id_kontr'] < 0) & (final_clean['id_kontr'] != -9999)]\n",
    "bad_cards = list(bad_cards['id_card_int'].unique())\n",
    "len(bad_cards)\n",
    "# bad_cards.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(final_clean)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(bad_cards)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bad_cards = final_clean[final_clean['quantity'] < 0]\n",
    "bad_cards = list(bad_cards['id_card_int'].unique())\n",
    "final_clean = final_clean[~final_clean.id_card_int.isin(bad_cards)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bad_cards = final_clean[final_clean['sum'] < 0]\n",
    "bad_cards = list(bad_cards['id_card_int'].unique())\n",
    "final_clean = final_clean[~final_clean.id_card_int.isin(bad_cards)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bad_cards = final_clean[(final_clean['id_kontr'] < 0) & (final_clean['id_kontr'] != -9999)]\n",
    "bad_cards = list(bad_cards['id_card_int'].unique())\n",
    "final_clean = final_clean[~final_clean.id_card_int.isin(bad_cards)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bad_cards = final_clean[(final_clean['quantity'] > 20)]\n",
    "bad_cards.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(bad_cards)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "quantities = final_clean.groupby(['id_card_int'])['quantity'].nunique()\n",
    "quantities = quantities.sort_values(ascending=False)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "n, bins, rectangles = ax.hist(quantities, 50)\n",
    "fig.canvas.draw()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}